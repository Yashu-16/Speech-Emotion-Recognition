Speech Emotion Recognition
A comprehensive machine learning project that recognizes human emotions from speech using both classical ML and deep learning approaches.
ğŸ‘¥ Team Members
Yash Randhe

ğŸ“‹ Project Overview
This project implements a Speech Emotion Recognition system capable of detecting emotions such as happiness, anger, sadness, and neutrality from audio recordings. It uses multiple approaches including:

Classical Machine Learning (SVM, Random Forest)
Deep Learning (CNN, Feedforward Neural Networks)
Ensemble Methods (Voting, Weighted Fusion)

ğŸ¯ Features

âœ… Extract 74 acoustic features (MFCCs, pitch, energy, spectral features)
âœ… Train multiple ML models and compare performance
âœ… Implement ensemble techniques for improved accuracy
âœ… Generate comprehensive visualizations (spectrograms, t-SNE, confusion matrices)
âœ… Achieve 75-90% accuracy with ensemble methods

ğŸ“Š Datasets

RAVDESS: 1,440 audio files from 24 actors expressing 8 emotions
CREMA-D: 7,442 clips from 91 actors expressing 6 emotions

Download Datasets:

RAVDESS: https://zenodo.org/record/1188976
CREMA-D: https://github.com/CheyneyComputerScience/CREMA-D

ğŸš€ Installation
Prerequisites

Python 3.8 or higher
pip package manager

Setup

Clone the repository:

bashgit clone https://github.com/YOUR_USERNAME/speech-emotion-recognition.git
cd speech-emotion-recognition

Create virtual environment:

bash# Windows
python -m venv env
.\env\Scripts\activate

# Linux/Mac
python3 -m venv env
source env/bin/activate

Install dependencies:

bashpip install -r requirements.txt

Download datasets:

Download RAVDESS and extract to data/ravdess/
Download CREMA-D (AudioWAV) and extract to data/crema_d/AudioWAV/



ğŸ“ Project Structure
speech-emotion-recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ravdess/              # RAVDESS dataset
â”‚   â””â”€â”€ crema_d/              # CREMA-D dataset
â”œâ”€â”€ step1_data_exploration.py
â”œâ”€â”€ step2_feature_extraction.py
â”œâ”€â”€ step3_classical_ml.py
â”œâ”€â”€ step4_deep_learning.py
â”œâ”€â”€ step5_fusion_visualization.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ® Usage
Run the scripts in order:
Step 1: Data Exploration
bashpython step1_data_exploration.py

Loads and visualizes audio files
Creates dataset catalogs
Generates spectrograms

Step 2: Feature Extraction
bashpython step2_feature_extraction.py

Extracts 74 acoustic features per audio file
Saves features to CSV files
Visualizes feature distributions

Step 3: Classical ML Models
bashpython step3_classical_ml.py

Trains SVM and Random Forest models
Generates confusion matrices
Compares model performance

Step 4: Deep Learning Models
bashpython step4_deep_learning.py

Trains CNN and Feedforward Neural Networks
Implements early stopping and checkpointing
Plots training history

Step 5: Model Fusion & Visualization
bashpython step5_fusion_visualization.py

Implements ensemble methods
Creates t-SNE and PCA visualizations
Generates final comparison report

ğŸ“ˆ Results
ModelAccuracySVM60-75%Random Forest65-80%Feedforward NN65-80%CNN70-85%Ensemble (Hard Voting)75-88%Ensemble (Soft Voting)75-90%
ğŸ”¬ Methodology
Feature Extraction

MFCCs (52 features): Mel-frequency cepstral coefficients
Pitch (4 features): Fundamental frequency statistics
Energy (4 features): RMS energy measures
Spectral (6 features): Centroid, bandwidth, rolloff
ZCR (4 features): Zero-crossing rate
Chroma (4 features): Pitch class profiles

Model Architectures
Feedforward Neural Network:
Input (74) â†’ Dense(256) â†’ Dense(128) â†’ Dense(64) â†’ Dense(32) â†’ Output
1D CNN:
Input â†’ Conv1D(64) â†’ Conv1D(128) â†’ Conv1D(256) â†’ Dense(128) â†’ Output
ğŸ“Š Visualizations
The project generates:

Waveforms and spectrograms
Confusion matrices for all models
t-SNE embeddings of feature space
PCA projections
Training history curves
Model comparison charts

ğŸ› ï¸ Technologies Used

Python 3.x
TensorFlow/Keras: Deep learning models
Scikit-learn: Classical ML models
Librosa: Audio processing
NumPy & Pandas: Data manipulation
Matplotlib & Seaborn: Visualization

ğŸ“ Academic Context
This project was developed for CPE646 Pattern Recognition course.
License
This project is licensed under the MIT License - see the LICENSE file for details.

Acknowledgments

RAVDESS dataset creators
CREMA-D dataset creators
Librosa development team
TensorFlow/Keras team
